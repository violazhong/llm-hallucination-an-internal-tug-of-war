# LLM Hallucination: An Internal Tug of War

## A Mechanistic Investigation into the Roots of Confident Hallucination in Llama-2
This repository contains the code and findings from a research sprint investigating a surprising "Confidence Bias" in Llama-2-13b-chat-hf. Our results reveal a specific, biased circuit that provides a direct, mechanistic explanation for the "incentivized guessing" phenomenon described by OpenAI (2024), suggesting a root cause for confident hallucination.